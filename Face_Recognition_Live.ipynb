{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## In questa sezione importiamo tutte le librerie necessarie: `face_recognition` per l'elaborazione dei volti, `cv2` per la gestione dei flussi video tramite OpenCV, e `numpy` per operazioni matematiche e gestione dei dati numerici."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import face_recognition\r\n",
    "import cv2\r\n",
    "import numpy as np"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Inizializziamo la videocamera integrata (indice 0), necessaria per acquisire in tempo reale i frame video da analizzare per il riconoscimento facciale."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "video_capture = cv2.VideoCapture(0)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Carichiamo le immagini di riferimento e ne estraiamo l'embedding facciale. Questi vettore numerico rappresenta le caratteristiche distintive di ogni volto."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "stefano_image = face_recognition.load_image_file(\"dataset/stenni.jpg\")\r\n",
    "stefano_face_encoding = face_recognition.face_encodings(stefano_image)[0]\r\n",
    "\r\n",
    "raoul_image = face_recognition.load_image_file(\"dataset/raoul.jpg\")\r\n",
    "raoul_face_encoding = face_recognition.face_encodings(raoul_image)[0]\r\n",
    "\r\n",
    "antonio_image = face_recognition.load_image_file(\"dataset/antonio.jpg\")\r\n",
    "antonio_face_encoding = face_recognition.face_encodings(antonio_image)[0]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Creiamo due array: uno contenente gli embedding dei volti noti e l'altro i relativi nomi. Questi serviranno per confrontare e riconoscere i volti nei frame successivi."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "known_face_encodings = [\r\n",
    "    stefano_face_encoding,\r\n",
    "    raoul_face_encoding,\r\n",
    "    antonio_face_encoding\r\n",
    "]\r\n",
    "known_face_names = [\r\n",
    "    \"Stefano\",\r\n",
    "    \"Raoul\",\r\n",
    "    \"Antonio\"\r\n",
    "]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Inizializziamo le strutture dati che memorizzeranno, per ogni frame, le posizioni dei volti, i relativi embedding e i nomi riconosciuti."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "face_locations = []\r\n",
    "face_encodings = []\r\n",
    "face_names = []"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Loop principale del riconoscimento in tempo reale:\r\n",
    "- Acquisizione del frame dalla webcam;\r\n",
    "- Estrazione e codifica dei volti;\r\n",
    "- Confronto con i volti noti per determinarne l'identità;\r\n",
    "- Visualizzazione dei risultati con riquadri e nomi associati ai volti."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "while True:\r\n",
    "    # Leggi un singolo frame dalla webcam\r\n",
    "    ret, frame = video_capture.read()\r\n",
    "    if not ret:\r\n",
    "        break\r\n",
    "\r\n",
    "    # Ridimensiona il frame video a 1/4 delle dimensioni per una più veloce elaborazione del riconoscimento facciale\r\n",
    "    small_frame = cv2.resize(frame, (0, 0), fx=0.25, fy=0.25)\r\n",
    "\r\n",
    "    # Converte l'immagine da colore BGR (utilizzato da OpenCV) a colore RGB (utilizzato da face_recognition)\r\n",
    "    rgb = cv2.cvtColor(small_frame, cv2.COLOR_BGR2RGB)\r\n",
    "\r\n",
    "    # Trova tutti i volti e le codifiche dei volti nel frame video corrente\r\n",
    "    face_locations = face_recognition.face_locations(rgb)\r\n",
    "\r\n",
    "    if face_locations:\r\n",
    "        face_encodings = face_recognition.face_encodings(rgb, face_locations)\r\n",
    "\r\n",
    "        face_names = []\r\n",
    "\r\n",
    "        for (top, right, bottom, left), face_encoding in zip(face_locations, face_encodings):\r\n",
    "            # Verifica se il volto corrisponde a uno dei volti noti\r\n",
    "            matches = face_recognition.compare_faces(known_face_encodings, face_encoding)\r\n",
    "            name = \"Sconosciuto\"\r\n",
    "\r\n",
    "            # Oppure, utilizza il volto noto con la distanza minore rispetto al nuovo volto\r\n",
    "            face_distances = face_recognition.face_distance(known_face_encodings, face_encoding)\r\n",
    "            best_match_index = np.argmin(face_distances)\r\n",
    "            confidence = 1 - face_distances[best_match_index]  # valore tra 0 e 1\r\n",
    "\r\n",
    "            if matches[best_match_index] and confidence >= 0.1:\r\n",
    "                name = f\"{known_face_names[best_match_index]} ({int(confidence * 100)}%)\"\r\n",
    "\r\n",
    "            # Salva anche le coordinate del volto\r\n",
    "            face_names.append((name, (top, right, bottom, left)))\r\n",
    "\r\n",
    "    # Mostra i risultati\r\n",
    "    for name, (top, right, bottom, left) in face_names:\r\n",
    "        # Scala le coordinate del volto alla dimensione originale (erano state ridotte di 1/4)\r\n",
    "        top *= 4\r\n",
    "        right *= 4\r\n",
    "        bottom *= 4\r\n",
    "        left *= 4\r\n",
    "\r\n",
    "        # Disegna un riquadro attorno al volto\r\n",
    "        cv2.rectangle(frame, (left, top), (right, bottom), (0, 0, 255), 2)\r\n",
    "\r\n",
    "        # Disegna un'etichetta con il nome sotto il volto\r\n",
    "        cv2.rectangle(frame, (left, bottom - 35), (right, bottom), (0, 0, 255), cv2.FILLED)\r\n",
    "        cv2.putText(frame, name, (left + 6, bottom - 6), cv2.FONT_HERSHEY_DUPLEX, 0.7, (255, 255, 255), 1)\r\n",
    "\r\n",
    "    # Mostra il frame risultante\r\n",
    "    cv2.imshow('Video - Premi Q per uscire', frame)\r\n",
    "\r\n",
    "    # Esci se premi 'q'\r\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\r\n",
    "        break\r\n",
    "\r\n",
    "# Rilascia la webcam e chiudi le finestre\r\n",
    "video_capture.release()\r\n",
    "cv2.destroyAllWindows()"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}