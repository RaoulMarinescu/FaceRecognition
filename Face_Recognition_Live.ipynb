{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66090727",
   "metadata": {},
   "source": [
    "##### In questa sezione importiamo tutte le librerie necessarie: `face_recognition` per l'elaborazione dei volti, `cv2` per la gestione dei flussi video tramite OpenCV, e `numpy` per operazioni matematiche e gestione dei dati numerici."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e0e6de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import face_recognition\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83553566",
   "metadata": {},
   "source": [
    "## Inizializziamo la videocamera integrata (indice 0), necessaria per acquisire in tempo reale i frame video da analizzare per il riconoscimento facciale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a95f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_capture = cv2.VideoCapture(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3486bd10",
   "metadata": {},
   "source": [
    "## Carichiamo le immagini di riferimento e ne estraiamo l'embedding facciale. Questi vettore numerico rappresenta le caratteristiche distintive di ogni volto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36607d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "stefano_image = face_recognition.load_image_file(\"dataset/stenni.jpg\")\n",
    "stefano_face_encoding = face_recognition.face_encodings(stefano_image)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7149dd91",
   "metadata": {},
   "source": [
    "## Load a second sample picture and learn how to recognize it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc705aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "raoul_image = face_recognition.load_image_file(\"dataset/raoul.jpg\")\n",
    "raoul_face_encoding = face_recognition.face_encodings(raoul_image)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb89c8fe",
   "metadata": {},
   "source": [
    "## Carica una seconda immagine e impara a riconoscerla."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e496cbf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "antonio_image = face_recognition.load_image_file(\"dataset/antonio.jpg\")\n",
    "antonio_face_encoding = face_recognition.face_encodings(antonio_image)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c1f87cf",
   "metadata": {},
   "source": [
    "## Creiamo due array: uno contenente gli embedding dei volti noti e l'altro i relativi nomi. Questi serviranno per confrontare e riconoscere i volti nei frame successivi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e688f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "known_face_encodings = [\n",
    "    stefano_face_encoding,\n",
    "    raoul_face_encoding,\n",
    "    antonio_face_encoding\n",
    "]\n",
    "known_face_names = [\n",
    "    \"Stefano\",\n",
    "    \"Raoul\",\n",
    "    \"Antonio\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef310657",
   "metadata": {},
   "source": [
    "## Inizializziamo le strutture dati che memorizzeranno, per ogni frame, le posizioni dei volti, i relativi embedding e i nomi riconosciuti."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b01fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "face_locations = []\n",
    "face_encodings = []\n",
    "face_names = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f71e9c85",
   "metadata": {},
   "source": [
    "### Loop principale del riconoscimento in tempo reale:\n",
    "- Acquisizione del frame dalla webcam;\n",
    "- Estrazione e codifica dei volti;\n",
    "- Confronto con i volti noti per determinarne l'identitÃ ;\n",
    "- Visualizzazione dei risultati con riquadri e nomi associati ai volti."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b39d2a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    # Leggi un singolo frame dalla webcam\n",
    "    ret, frame = video_capture.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # 0 per flipping verticale\n",
    "    # frame = cv2.flip(frame, 0)\n",
    "\n",
    "    # Resize frame of video to 1/4 size for faster face recognition processing\n",
    "    small_frame = cv2.resize(frame, (0, 0), fx=0.25, fy=0.25)\n",
    "\n",
    "    # Convert the image from BGR color (which OpenCV uses) to RGB color (which face_recognition uses)\n",
    "    rgb = cv2.cvtColor(small_frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Find all the faces and face encodings in the current frame of video\n",
    "    face_locations = face_recognition.face_locations(rgb)\n",
    "\n",
    "    if face_locations:\n",
    "        face_encodings = face_recognition.face_encodings(rgb, face_locations)\n",
    "\n",
    "        face_names = []\n",
    "\n",
    "        for (top, right, bottom, left), face_encoding in zip(face_locations, face_encodings):\n",
    "            # See if the face is a match for the known face(s)\n",
    "            matches = face_recognition.compare_faces(known_face_encodings, face_encoding)\n",
    "            name = \"Sconosciuto\"\n",
    "\n",
    "            # Or instead, use the known face with the smallest distance to the new face\n",
    "            face_distances = face_recognition.face_distance(known_face_encodings, face_encoding)\n",
    "            best_match_index = np.argmin(face_distances)\n",
    "            confidence = 1 - face_distances[best_match_index]  # valore tra 0 e 1\n",
    "\n",
    "            if matches[best_match_index] and confidence >= 0.1:\n",
    "                name = f\"{known_face_names[best_match_index]} ({int(confidence * 100)}%)\"\n",
    "\n",
    "            face_names.append((name, (top, right, bottom, left)))  # salva anche le coordinate\n",
    "\n",
    "    # Display the results\n",
    "    for name, (top, right, bottom, left) in face_names:\n",
    "        # Scale back up face locations since the frame we detected in was scaled to 1/4 size\n",
    "        top *= 4\n",
    "        right *= 4\n",
    "        bottom *= 4\n",
    "        left *= 4\n",
    "\n",
    "        # Draw a box around the face\n",
    "        cv2.rectangle(frame, (left, top), (right, bottom), (0, 0, 255), 2)\n",
    "\n",
    "        # Draw a label with a name below the face\n",
    "        cv2.rectangle(frame, (left, bottom - 35), (right, bottom), (0, 0, 255), cv2.FILLED)\n",
    "        cv2.putText(frame, name, (left + 6, bottom - 6), cv2.FONT_HERSHEY_DUPLEX, 0.7, (255, 255, 255), 1)\n",
    "        # cv2.putText(frame, name, (left, top - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255, 255, 255), 2)\n",
    "\n",
    "    # Mostra il frame risultante\n",
    "    cv2.imshow('Video - Premi Q per uscire', frame)\n",
    "\n",
    "    # Esci se premi 'q'\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Rilascia la webcam e chiudi le finestre\n",
    "video_capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
